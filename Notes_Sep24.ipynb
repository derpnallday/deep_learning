{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras, overfitting and regulariation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization -underfitting and overfitting\n",
    "\n",
    "**L-Norm regularization (Lasso)**: \"introduce a cost for large weights\"\n",
    "\n",
    "$$C = Loss + Regularization term$$\n",
    "\n",
    "**L1:** $ Loss + \\lambda\\sum_{l=1}^{L}||W_1|| $\n",
    "\n",
    "**L2:** $ Loss + \\lambda\\sum_{l=1}^{L}||W_1^2|| $\n",
    "\n",
    "\n",
    "**Dropout**\n",
    "\n",
    "In each SGD step, randomly ignore a fraction $p$ of neurons\n",
    "- can select $p$ in wide range. Typical is 0.2-0.8, dependent on size of ANN\n",
    "- can apply only in specific layers. It is typical to only do dropout in a designated \"dropout layer\" somewhere close to output.\n",
    "> dropout helps to stop specific neurons from learning specific patterns and allows the model to generalize better\n",
    "\n",
    "**Data augmentation**\n",
    "\n",
    "Shear, shift, scale and/or rotate input data\n",
    "> not only generalizes better but also adds more data points\n",
    "\n",
    "**early stopping**\n",
    "\n",
    "stop training when performance on validation dataset starts worsening\n",
    "\n",
    "\n",
    "## Vanishing gradients - a problem in deep neural nets\n",
    "\n",
    "**Problem:**\n",
    "- Gradients closer and closer to the input tend to get smaller and smaller\n",
    "- Leads to smaller weight updates near input and larger weight updates near output\n",
    "\n",
    "**Solution:**\n",
    "- Use an activation function without small gradient for high values\n",
    "- candidate activate function: ReLU\n",
    "\n",
    "**Problems with ReLU:**\n",
    "- Exploding gradients\n",
    "\n",
    "**Solution:**\n",
    "- Batch normalization, gradient clipping, weight regularization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#to generate data\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "def generate_X_linear(N=200):\n",
    "    X = np.vstack([\n",
    "        np.random.normal([-2, -2], 1, size=(int(N/2), 2)),\n",
    "        np.random.normal([2, 2], 1, size=(int(N/2), 2))\n",
    "    ])\n",
    "\n",
    "    y = np.array([0] * int(N/2) + [1] * int(N/2)).reshape(-1, 1)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def generate_X_nonlinear(N=200, R=5):\n",
    "    X_inner = np.random.normal([0, 0], 1, size=(int(N/2), 2))\n",
    "\n",
    "    X_outer = np.array([\n",
    "        [R*np.cos(theta), R*np.sin(theta)]\n",
    "        for theta in np.linspace(0, 2 * np.pi, int(N/2))\n",
    "    ]) + np.random.randn(int(N/2), 2)\n",
    "\n",
    "    X = np.vstack([X_inner, X_outer])\n",
    "    y = np.array([0] * int(N/2) + [1] * int(N/2)).reshape(-1, 1)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "x, y = generate_X_nonlinear(1000)\n",
    "plt.title(\"Non-linear\", fontsize=12)\n",
    "plt.scatter(x[:, 0], x[:, 1], c=list(y.reshape(-1)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#building layers\n",
    "model.add(Dense(units=3, activation='relu', input_dim=2))\n",
    "model.add(Dense(units=1, activation='relu', input_dim=3))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.0406 - accuracy: 0.9690 - mse: 0.0406\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0407 - accuracy: 0.9690 - mse: 0.0407\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0407 - accuracy: 0.9690 - mse: 0.0407\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0406 - accuracy: 0.9670 - mse: 0.0406\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0406 - accuracy: 0.9710 - mse: 0.0406\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0406 - accuracy: 0.9660 - mse: 0.0406\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.0406 - accuracy: 0.9680 - mse: 0.0406\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0406 - accuracy: 0.9680 - mse: 0.0406\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.0407 - accuracy: 0.9660 - mse: 0.0407\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0407 - accuracy: 0.9680 - mse: 0.0407\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0406 - accuracy: 0.9690 - mse: 0.0406\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 0.0406 - accuracy: 0.9680 - mse: 0.0406\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.0406 - accuracy: 0.9700 - mse: 0.0406\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 0s 20us/step - loss: 0.0406 - accuracy: 0.9670 - mse: 0.0406\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0406 - accuracy: 0.9680 - mse: 0.0406\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.0406 - accuracy: 0.9680 - mse: 0.0406\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 0.0406 - accuracy: 0.9680 - mse: 0.0406\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0406 - accuracy: 0.9700 - mse: 0.0406\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0406 - accuracy: 0.9680 - mse: 0.0406\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0406 - accuracy: 0.9670 - mse: 0.0406\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0405 - accuracy: 0.9710 - mse: 0.0405\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0406 - accuracy: 0.9680 - mse: 0.0406\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0405 - accuracy: 0.9690 - mse: 0.0405\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0405 - accuracy: 0.9670 - mse: 0.0405\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0406 - accuracy: 0.9690 - mse: 0.0406\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0406 - accuracy: 0.9690 - mse: 0.0406\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.0405 - accuracy: 0.9690 - mse: 0.0405\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0404 - accuracy: 0.9710 - mse: 0.0404\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0405 - accuracy: 0.9710 - mse: 0.0405\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0406 - accuracy: 0.9720 - mse: 0.0406\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0405 - accuracy: 0.9700 - mse: 0.0405\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0405 - accuracy: 0.9690 - mse: 0.0405\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0405 - accuracy: 0.9720 - mse: 0.0405\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0404 - accuracy: 0.9710 - mse: 0.0404\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0405 - accuracy: 0.9700 - mse: 0.0405\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.0404 - accuracy: 0.9680 - mse: 0.0404\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0405 - accuracy: 0.9730 - mse: 0.0405\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0405 - accuracy: 0.9720 - mse: 0.0405\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0406 - accuracy: 0.9680 - mse: 0.0406\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0405 - accuracy: 0.9700 - mse: 0.0405\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0405 - accuracy: 0.9710 - mse: 0.0405\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0406 - accuracy: 0.9700 - mse: 0.0406\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.0405 - accuracy: 0.9690 - mse: 0.0405\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0405 - accuracy: 0.9720 - mse: 0.0405\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0404 - accuracy: 0.9700 - mse: 0.0404\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.0405 - accuracy: 0.9710 - mse: 0.0405\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.0404 - accuracy: 0.9700 - mse: 0.0404\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.0405 - accuracy: 0.9690 - mse: 0.0405\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.0405 - accuracy: 0.9690 - mse: 0.0405\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.0404 - accuracy: 0.9700 - mse: 0.0404\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x, y, epochs=50, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-rc0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
